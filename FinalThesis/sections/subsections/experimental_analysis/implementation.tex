In this section, we describe the software package developed as part of this work. The package is written in C++, and has various levels of performance capabilities. It can additionally be run using the Lemon Graph Library~\cite{lemon}, or with purely internal data structure implementations. The various implementations allow users to run the various algorithms described in sec.~\ref{sec:algos} either with a single thread, or under a producer-consumer framework for parallel processing. Additionally, a finite memory implementation is provided, and a memoization approach on the input sequence is implemented allowing for increased efficiency. Finally, example code for running the software on a High Throughput Cluster using Condor~\cite{htcondor} is provided.

\subsubsection*{Basic structures}

The most basic structure in the software package is the \texttt{Mspace} class. This class uses a \texttt{std::vector} to store the graph as an adjacency matrix of distances between nodes. Functions such as \texttt{setSize}, \texttt{getSize}, \texttt{getDistance}, and \texttt{setDistance} allow for easy manipulation of the metric space.

\texttt{getInput} and \texttt{writeOutput} classes are written to help maintain RAII standards, and allow for easy reading and writing of input and output files. 

An abstract \texttt{Alg} class is provided as a framework for each of the various algorithms to build off of. This class defines all basic functionality for an algorithm to run, and has a virtual function \texttt{run} that must be implemented by each algorithm, which takes an input request sequence and returns the cost incurred by the algorithm. It contains a \texttt{Mspace} object, and stores the current configuration of the servers in two forms: a \texttt{config} vector which stores the integer location of each server, as well as a \texttt{coverage} vector that stores whether or not each location in the metric space is covered by a server. This allows for efficient checking of whether or not a location is covered by a server, as well as efficient access to where the servers are located. \texttt{setServers} and \texttt{setGraph} functions are provided to allow for easy initialization of the algorithm, and a \texttt{moveServer} function is provided for easy manipulation of the server configuration.

\subsubsection*{Algorithm Implementations}

The \texttt{Alg} class is inherited by each of the various algorithm implementations. Each algorithm has a \texttt{run} function that takes an input request sequence and returns the cost incurred by the algorithm. Algorithms \texttt{doubleCoverageAlg}, \texttt{lazydoubleCoverageAlg} and \texttt{KCentersAlg} only work on line metric spaces, and so have a check to insure that the input metric space is a line. The \texttt{doubleCoverageTreeAlg} is the extension of the \texttt{doubleCoverageAlg} to work on trees, but has no check to ensure that the given metric space is a tree. Additional algorithm implementations designed to work on generic metric spaces include a \texttt{randomAlg} that randomly chooses which server to move, \texttt{greedyAlg}, \texttt{WFAlg}, and \texttt{optAlg} which operates on the entire request sequence at once. \texttt{WFAlg} uses a min cost flow problem formulation, as described in sec.~\ref{sec:mcfp}. \texttt{optAlg} uses a similar formulation, which is described in~\cite{mcfp2011}. Solvers for these are provided in two classes, \texttt{mcfp} and \texttt{lemon\_mcfp}. The \texttt{mcfp} uses a custom graph implementation and a provided solver, allowing for a stand-alone build. the \texttt{lemon\_mcfp} solver constructs the graph within the Lemon Graph Library data structures, and uses the Lemon solvers allowing for a 6x speedup~\cite{lemon}. Both of these are implemented in spereate classes to once again help maintain RAII standards. While the most recent efficient implementation design does not use these classes for the algorithms, they are still provided for ease of understnading.

\subsubsection*{Analysis Implementations}

The most basic mechanism for running the algorithsm is provided in the \texttt{csv\_parser} file. This provides methods for reading the input and output file names, and then reading and constructing the metric space from the input csv file. For each input, the various algorithm are run and their costs are saved in a vector. The output costs are then written to a csv file along with their associated algorithm names and the request sequence they correspond to. This implementation struggles due to its sequential nature, and unbounded memory usage.

The next implementaiton, \texttt{csv\_parser\_parralel}, uses \texttt{OpenMP}~\cite{openmp08} to parallelize the algorithm runs across multiple cores. This requires \texttt{OpenMP} to be installed, and for the program to be compiled with the appropriate flags. This is a simple parallelization of the above implementation, but still struggles from unbounded memory usage.

The \texttt{csv\_parser\_parralel2} implements a producer-consumer framework with the thread strucuture provided by the \texttt{C++11} standard. This implementation launches multiple consumer threads which individually run each request sequence, and then push results to a \texttt{buffer} class implementaition. A consumer thread then reads from the buffer and writes the results to the output file. This allows for a smaller amount of memory usage, and a more efficient use of the available resources.


The final implementation uses a memoization approach to increase efficiency. This is possisble due to the nature of the \KS problem. For a request sequence of length $i$, any online algorithm $ALG$ will have the exact same result (with the exception of \texttt{randAlg}) for the first $i-1$ inputs, regardless of the $i$th input. this means that for a metric space consisting of 10 points, we are computing costs for request sequences of length $i-1$ 10 times more than we actually need to when following the previous approaches. The \texttt{all\_efficient} implementation saves multiple configuration / request sequence states for each algorithm in memory, allowing it to reuse the results of previous runs. It additionally still utilizes the producer-consumer framework implemented in \texttt{csv\_parser\_parralel2}. This allows for a significant speedup in the computation of the costs for each algorithm, with the use of slightly more memory.

Additionally, example \texttt{.sub} scripts are provided for use on a High Throughput Cluster using Condor. This allows for easy submission of multiple jobs to the cluster~\cite{htcondor}. 

\subsubsection*{Input Generation}

There are various files provided dedicated to generating different inputs in a \texttt{csv} file format. Each file behaves very similarly, with variance in the type of metric space generated. Unfortunately, some files may be outdated and generate additional information that is hard-coded in the more recent analysis implementations. All of these assume unit lengths between any two connected nodes. The \texttt{generateInputLine} and \texttt{generateInputCircle} are the most basic input generation mechanisms, which generate metric spaces for lines and circles. These both have the parameters hard-coded in the files, and must be manually modified and recompiled to get various numbers of points on the line and various numbers of servers.

The \texttt{generateStar} and \texttt{generateStar1} files each generate Multiray spaces, with the \texttt{generateStar1} having the restriction that each node other than $c$ is connected \textit{only} to $c$, with a unit length. These must also have the parameters modified within the files.

Finally, the \texttt{generateInputCaterpillar} file will generate a reduced caterpillar graph as described above. It takes three parameters as input when run as an exectuable: the number of nodes on the central path, the number of requests per request sequence, and the number of servers to run with. 

It is worth noting that for the most advanced analysis methods, some variables such as the input request sequence lengths and number of servers are hard-coded within the analysis tool. Earlier versions take these as input along with the metric space.