\subsection{Outline}
\label{sec:out}
In this paper, we consider the \KS problem in a variety of contexts. First, we provide a description of the \KS problem, and an in-depth proof of the $2k-1$ competitiveness of the Work Function Algorithm (WFA). Following this a literature review is provided, focusing on the Unifying Potential for the WFA~\cite{unifyingPotential2021}. We then have an analysis of~\cite{unifyingPotential2021}, and provide some thoughts into a potential extension of this work for caterpillar graphs. Following this, we transition to an analysis of other algorithms focusing on the bijective analysis of these algorithms, and describe a \CC environment provided for practical testing of a variety of these algorithms. We provide some experimental analysis of the algorithms within the testing suite, extending the work done in~\cite{independantStudy2023}.

\subsection{Problem Description}
\label{sec:desc}
An instance of the \KS problem can be described by a metric space $M = (X, d)$, a number of servers $k>1$, and an input sequence $\sigma = (r_1, r_2, r_3, ..., r_n)$, where each $r_i$ corresponds to a point in the metric space. Each of the $k$ servers is assigned an initial starting location within the metric space (generally this is assumed to be the first $k$ requests of the input sequence). Following this, The sequence of reqeusts is processed one at a time. When a request comes in, a given algorithm \textit{ALG} must decide on one of the servers to service the request. It must then move said server from it's current location $x$ to the request $r_i$. This incurs a cost of $c = d(x, r_i)$. The goal is to have \textit{ALG} incur the smallest possible cost while servicing all of the requests in the sequence~\cite{OnlineComp1998}.
\\ \\
There are two major distinctions to be made between different classes of algorithms. The first is the classification of a "lazy" algorithm - one that only moves a server in order to service the current request. Non-lazy algorithms will process a request, and then potentially also move other servers preemptively in order to prepare for future requests. It is important to note that for any non-lazy algorithm that performs well, there is a parallel lazy algorithm that performs just as well, if not better. We can describe this algorithm as follows: suppose we have our non-lazy algorithm, \textit{ALG}. We have the algorithm \textit{LAZY} service requests with the same servers that \textit{ALG} services requests. Suppose that \textit{ALG} moves a server from location $x_1$ to location $x_2$ preemptively, and then later services request $r_i$ with this server. \textit{LAZY} will be servicing $r_i$ with the same server, except it will be moving directly from $x_1$ instead of $x_2$. By the triangle inequality, $d(x_1, r_i) \leq d(x_1, x_2) + d(x_2, r_i)$. By applying this principle throughout the request sequence, we will see that the cost of \textit{LAZY} will be as good if not better than that of \textit{ALG}. This shows us that we can create a lazy algorithm from a non-lazy algorithm by maintaining "ghost" locations for servers in relation to how the non-lazy algorithm would use them. Then, we can determine which server the non-lazy algorithm would use, and then service that location with the correct server~\cite{OnlineComp1998}.
\\ \\
The second major distinction is between "online" and "offline" algorithms. An offline algorithm receives the entire request sequence at once, and so as a result is able to make decisions on what server to use for the current request based off of future requests. In contrast, an online algorithm receives the request one at a time, and so is only able to make decisions based off of past requests, the current server configuration, and the current request. While online algorithms are at a severe disadvantage due to this, real world applications often rely on the performance of these algorithms. Applications range from disk access optimization, such as the two headed-disk problem~\cite{OnlineComp1998}, to police or firetruck servicing.

\subsection{Competitive Analysis}
\label{sec:compAna}
The most popular method for analyzing the performance of online algorithms for a problem is competitive analysis. Here, we assume a "malicious adversary", who is attempting to make our algorithm \textit{ALG} perform as poorly as possible in relation to the performance of the optimal algorithm \textit{OPT}. The malicious adversary is allowed to come up with any finite input, and our competitive ratio is determined by this. If for any finite input, we are able to guaruntee that \textit{ALG} has a cost within a certain ratio $c$ of \textit{OPT} (allowing for a constant additive factor), then we say that our algorithm is $c$-competitive~\cite{OnlineComp1998}. So, if we define $ALG(\sigma)$ as the cost \textit{ALG} incurs while processing request $\sigma$, then we have the following definition: 

\begin{definition}
\label{def:comp}
Algorithm \textit{ALG} is said to be \textbf{\textit{c}-competitive} if for every finite request sequence \s, $ALG(\sigma) \leq c\cdot OPT(\sigma)+\alpha$ for some constant $\alpha$.
\end{definition}

Competitive analysis is in some sense similar to "worst case" analysis, where we try to see how poorly an algorithm will ever perform. It is worth noting that some algorithms such as a greedy algorithm may perform very well on the majority of inputs, but given specific inputs may not be competitive at all. That is, given some value $c$, a finite length input can be found such that the algorithm doesn't satisfy the above definition. 
\\ \\
Additionally, a lower bound of $k$ has been shown for any online algorithm's competitive ratio. This means that if we are looking at the 3-Servers problem, the best competitive ratio an online algorithm can achieve is 3~\cite{OnlineComp1998}.